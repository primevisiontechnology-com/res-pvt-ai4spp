baseline: shared
baseline_kwargs: {}
batch_size: 4
data_dir: data/
dataloader_num_workers: 0
generate_default_data: false
log_on_step: true
lr_scheduler: null
lr_scheduler_interval: epoch
lr_scheduler_kwargs:
  gamma: 0.1
  milestones:
  - 80
  - 95
lr_scheduler_monitor: val/reward
metrics: {}
num_augment: 8
num_starts: null
optimizer: Adam
optimizer_kwargs:
  lr: 0.0001
policy_kwargs:
  select_start_nodes_fn: &id001 !!python/name:rl4co.utils.ops.select_start_nodes ''
select_start_nodes_fn: *id001
shuffle_train_dataloader: false
test_batch_size: null
test_data_size: 10000
train_data_size: 500
use_dihedral_8: true
val_batch_size: null
val_data_size: 100
