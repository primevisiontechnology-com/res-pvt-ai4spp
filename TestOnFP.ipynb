{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from FPenv import FPEnv\n",
    "\n",
    "# Recreate training env\n",
    "env = FPEnv(fp_path=\"Floorplans/quad-infeed/butterfly/14x11/floorplan.json\")\n",
    "\n",
    "# Load Trained Models\n",
    "model = torch.load('Models/TrainOnFloorplansResults5.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c513fb50d77c22d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5db7d0b8ebd68e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test trained model on grid map with obstacles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d71305ee81666d9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from astar import AStarSearch\n",
    "from SPPv2env import SPPv2Env\n",
    "\n",
    "infer_env = SPPv2Env(num_loc=100)\n",
    "td_init = infer_env.reset(batch_size=[4]).to(device)\n",
    "\n",
    "policy = model.policy.to(device)\n",
    "out = policy(td_init.clone(), infer_env, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "actions_trained = out['actions'].cpu().detach()\n",
    "\n",
    "# run A* search on the environment\n",
    "astar = AStarSearch(td_init.clone())\n",
    "astar_out = astar.search()\n",
    "actions_astar = astar_out[\"actions\"].cpu().detach()\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "for i, td in enumerate(td_init):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(11,5))\n",
    "\n",
    "    infer_env.render(td, actions_trained[i], ax=axs[0])\n",
    "    axs[0].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")\n",
    "\n",
    "    infer_env.render(td, actions_astar[i], ax=axs[1])\n",
    "    axs[1].set_title(\"A* Search | Cost = {:.3f}\".format(-astar_out[\"reward\"][i].item()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fdd5d6c17694c0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Real Floorplan Path Finding with Reinforcement Learning and Astar Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a07b5485836ba6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Salt Lake City Floorplan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb6a3e28cf2ee5cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FPenv import FPEnv\n",
    "from astar import AStarSearch\n",
    "import torch\n",
    "\n",
    "# Setup a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "infer_env = FPEnv(fp_path=\"Floorplans/USPS/0026_Salt_Lake_City/floorplan.json\")\n",
    "td_init = infer_env.reset(batch_size=[4]).to(device)\n",
    "\n",
    "\n",
    "# Function to check for NaNs in a tensor dictionary\n",
    "nan_found = False\n",
    "for key, tensor in td_init.items():\n",
    "    if torch.isnan(tensor).any():\n",
    "        nan_found = True\n",
    "        print(f\"NaN values found in tensor '{key}'\")\n",
    "if not nan_found:\n",
    "    print(\"No NaN values found in the tensor dictionary.\")\n",
    "\n",
    "policy = model.policy.to(device)\n",
    "\n",
    "out = policy(td_init.clone(), infer_env, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "actions_trained = out['actions'].cpu().detach()\n",
    "\n",
    "# run A* search on the environment\n",
    "astar = AStarSearch(td_init.clone())\n",
    "astar_out = astar.search()\n",
    "actions_astar = astar_out[\"actions\"].cpu().detach()\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "for i, td in enumerate(td_init):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(11,5))\n",
    "\n",
    "    infer_env.render(td, actions_trained[i], ax=axs[0])\n",
    "    axs[0].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")\n",
    "\n",
    "    infer_env.render(td, actions_astar[i], ax=axs[1])\n",
    "    axs[1].set_title(\"A* Search | Cost = {:.3f}\".format(-astar_out[\"reward\"][i].item()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be2c7bc1ac30134"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Butterfly 14 x 11 Floorplan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d830a1974fae65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FPenv import FPEnv\n",
    "from astar import AStarSearch\n",
    "import torch\n",
    "\n",
    "# Setup a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "infer_env = FPEnv(fp_path=\"Floorplans/quad-infeed/butterfly/14x11/floorplan.json\")\n",
    "td_init = infer_env.reset(batch_size=[4]).to(device)\n",
    "\n",
    "\n",
    "# Function to check for NaNs in a tensor dictionary\n",
    "nan_found = False\n",
    "for key, tensor in td_init.items():\n",
    "    if torch.isnan(tensor).any():\n",
    "        nan_found = True\n",
    "        print(f\"NaN values found in tensor '{key}'\")\n",
    "if not nan_found:\n",
    "    print(\"No NaN values found in the tensor dictionary.\")\n",
    "\n",
    "policy = model.policy.to(device)\n",
    "\n",
    "out = policy(td_init.clone(), infer_env, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "actions_trained = out['actions'].cpu().detach()\n",
    "\n",
    "# run A* search on the environment\n",
    "astar = AStarSearch(td_init.clone())\n",
    "astar_out = astar.search()\n",
    "actions_astar = astar_out[\"actions\"].cpu().detach()\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "for i, td in enumerate(td_init):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(11,5))\n",
    "\n",
    "    infer_env.render(td, actions_trained[i], ax=axs[0])\n",
    "    axs[0].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")\n",
    "\n",
    "    infer_env.render(td, actions_astar[i], ax=axs[1])\n",
    "    axs[1].set_title(\"A* Search | Cost = {:.3f}\".format(-astar_out[\"reward\"][i].item()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b2c75d69b8911c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Floorplans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f37d411c60226026"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FPenv import FPEnv\n",
    "from astar import AStarSearch\n",
    "from Floorplan_Codes.utils import get_paths\n",
    "import torch\n",
    "\n",
    "# Setup a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "floorplans = get_paths(\"floorplan.json\", \"Floorplans/USPS\", recursive=True, depth=1)\n",
    "ids = []\n",
    "for floorplan in floorplans:\n",
    "    try:\n",
    "        infer_env = FPEnv(fp_path=floorplan)\n",
    "        td_init = infer_env.reset(batch_size=[4]).to(device)\n",
    "\n",
    "\n",
    "        # Function to check for NaNs in a tensor dictionary\n",
    "        nan_found = False\n",
    "        for key, tensor in td_init.items():\n",
    "            if torch.isnan(tensor).any():\n",
    "              nan_found = True\n",
    "              print(f\"NaN values found in tensor '{key}'\")\n",
    "        if not nan_found:\n",
    "            print(\"No NaN values found in the tensor dictionary.\")\n",
    "\n",
    "        policy = model.policy.to(device)\n",
    "\n",
    "        out = policy(td_init.clone(), infer_env, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "        actions_trained = out['actions'].cpu().detach()\n",
    "\n",
    "        # run A* search on the environment\n",
    "        astar = AStarSearch(td_init.clone())\n",
    "        astar_out = astar.search()\n",
    "        actions_astar = astar_out[\"actions\"].cpu().detach()\n",
    "\n",
    "        # Plotting\n",
    "        import matplotlib.pyplot as plt\n",
    "        for i, td in enumerate(td_init):\n",
    "            fig, axs = plt.subplots(1,2, figsize=(11,5))\n",
    "\n",
    "            parts = floorplan.split('/')\n",
    "            site = parts[-2]\n",
    "            fig.suptitle(\"Floorplan: \" + site, fontsize=16)\n",
    "\n",
    "            infer_env.render(td, actions_trained[i], ax=axs[0])\n",
    "            axs[0].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")\n",
    "\n",
    "            infer_env.render(td, actions_astar[i], ax=axs[1])\n",
    "            axs[1].set_title(\"A* Search | Cost = {:.3f}\".format(-astar_out[\"reward\"][i].item()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6c0b705e5d1f7f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
